{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic few-shot prompting\n",
    "\n",
    "What we do in this notebook:\n",
    "\n",
    "1. Load synthetic data and embedding (generate with `model_name`).\n",
    "2. Define a function for dynamic few-shot prompting (i.e., dynamically select few-shot examples based on input similarity).\n",
    "3. Generate a response using `gp3-3.5-turbo` model.\n",
    "4. Compare the responses with and without dynamic few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "The **cosine similarity** between two vectors A and B is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{cosine\\_similarity}(A,B) = \\frac{A \\cdot B}{\\lVert A \\rVert \\lVert B \\rVert}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $A \\cdot B$ is the dot product of vectors $A$ and $B$.\n",
    "- $\\lVert A \\rVert$ and $\\lVert B \\rVert$ are the Euclidean norms of vectors $A$ and $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> np.float64:\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([4, 5, 6])\n",
    "cos_sim = cosine_similarity(v1, v2)\n",
    "print(f\"Cosine Similarity: {cos_sim}\")\n",
    "print(f\"type: {type(cos_sim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_1 = \"These are not the droids you are looking for\"\n",
    "input_text_2 = \"This is an example to test the function\"\n",
    "input_text_3 = \"This sentence is used as example to test the function\"\n",
    "input_embedding_1 = get_embedding(text=input_text_1, model=emb_model_name)\n",
    "input_embedding_2 = get_embedding(text=input_text_2, model=emb_model_name)\n",
    "input_embedding_3 = get_embedding(text=input_text_3, model=emb_model_name)\n",
    "\n",
    "print(f\"1 vs. 2 = {cosine_similarity(input_embedding_1, input_embedding_2)}\")\n",
    "print(f\"1 vs. 3 = {cosine_similarity(input_embedding_1, input_embedding_3)}\")\n",
    "print(f\"2 vs. 3 = {cosine_similarity(input_embedding_2, input_embedding_3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select closest examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_examples(input_text:str, examples:list , example_embeddings: list, emb_model_name:str, num_examples:int=3):\n",
    "    \"\"\"\n",
    "    Select the most relevant few-shot examples based on cosine similarity.\n",
    "    \"\"\"\n",
    "    input_embedding = get_embedding(text=input_text, model=emb_model_name)\n",
    "\n",
    "    # TODO: THIS MUST BE CHANGED TO AN EMBEDDING DATABASE     \n",
    "    similarities = [cosine_similarity(input_embedding, np.array(embedding)) for embedding in example_embeddings]\n",
    "    selected_indices = np.argsort(similarities)[-num_examples:][::-1]\n",
    "    return [examples[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"You're so dumb, no wonder we can't have a conversation!\"\n",
    "input_embedding = get_embedding(text=input_text, model=emb_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_examples(\n",
    "    input_text=input_text,\n",
    "    examples=syn_data_gpt_subset,\n",
    "    example_embeddings=embeddings_gpt,\n",
    "    emb_model_name=emb_model_name,\n",
    "    num_examples=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dailogy_sin_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
