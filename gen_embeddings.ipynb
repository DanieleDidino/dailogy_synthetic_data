{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embeddings\n",
    "\n",
    "What we do in this notebook:\n",
    "\n",
    "1. Load synthetic data.\n",
    "2. Generate embeddings with `model_name`.\n",
    "3. Define a function for dynamically select few-shot examples based on input similarity.\n",
    "4. Store the embeddins in a json file.\n",
    "\n",
    "This code will then be used to create a python script that performs these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/dailogy_synthetic_data/.venv_dailogy_sin_data/lib/python3.10/site-packages/environ/environ.py:639: UserWarning: /tmp/ipykernel_17289/.env doesn't exist - if you're not configuring your environment separately, create one.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import environ\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import sqlite3\n",
    "\n",
    "# Import OpenAI key\n",
    "env = environ.Env()\n",
    "environ.Env.read_env()\n",
    "API_KEY = env(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import json files\n",
    "\n",
    "Load one of the files with examples generated with `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: data_nb/synthetic_data_gpt.json\n"
     ]
    }
   ],
   "source": [
    "# Folder with synthetic data\n",
    "directory = Path('data_nb/')\n",
    "\n",
    "# Select all the files with examples generated with GPT\n",
    "matching_files = directory.glob('synthetic_data*gpt*.json')\n",
    "\n",
    "# Select one of the files\n",
    "for file_path in matching_files:\n",
    "    print(f\"Loading file: {file_path}\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        syn_data_gpt = json.load(file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dysfunctional': \"You always waste money on useless things! You're so irresponsible with our finances.\",\n",
       "  'functional': \"I've noticed we have different spending habits. Can we discuss how we can better manage our finances together?\"},\n",
       " {'dysfunctional': \"If you don't pay child support on time, I'll make sure you regret it.\",\n",
       "  'functional': \"It's important for both of us to fulfill our financial responsibilities. Can we find a way to ensure child support payments are made on time?\"},\n",
       " {'dysfunctional': \"You're a gold digger who only cares about money. I regret ever being with you.\",\n",
       "  'functional': \"Let's have a calm discussion about our financial disagreements and how we can move forward positively.\"},\n",
       " {'dysfunctional': \"I'll drain our joint account if you don't agree to my terms. You'll be left with nothing.\",\n",
       "  'functional': \"Let's work together to find a fair solution that respects both of our financial needs and concerns.\"},\n",
       " {'dysfunctional': \"You're always asking for more money, you're so greedy and selfish.\",\n",
       "  'functional': 'I feel like our financial expectations are not aligned. Can we talk about finding a balance that works for both of us?'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data_gpt[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one of the files with examples generated with `dolphin-mistral`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: synthetic_data/synthetic_data_dolphin_2024-06-18_11-46.json\n"
     ]
    }
   ],
   "source": [
    "# Folder with synthetic data\n",
    "directory = Path('synthetic_data')\n",
    "\n",
    "# Select all the files with examples generated with dolphin-mistral\n",
    "matching_files = directory.glob('synthetic_data*dolphin*.json')\n",
    "\n",
    "# Select one of the files\n",
    "for file_path in matching_files:\n",
    "    print(f\"Loading file: {file_path}\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        syn_data_dolphin = json.load(file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dysfunctional': \"You're such a bad money manager, always overspending and racking up debt.\",\n",
       "  'functional': \"I'm concerned about our financial situation. Let's have an open conversation to find solutions.\"},\n",
       " {'dysfunctional': \"If you don't start contributing more to the household expenses, I'll be forced to take legal action.\",\n",
       "  'functional': 'Can we discuss your contribution to our financial responsibilities and come up with an agreement?'},\n",
       " {'dysfunctional': \"I can't believe you're trying to take my child support payments away from me. What a low thing to do!\",\n",
       "  'functional': \"We need to address the issue of child support payments and come to an agreement that's fair for both parties.\"},\n",
       " {'dysfunctional': 'You never listen to me when we talk about money. You always have to be right and get your way.',\n",
       "  'functional': \"Let's try to compromise and work together to resolve our financial disagreements in a constructive manner.\"},\n",
       " {'dysfunctional': \"You don't care about anything but yourself. You're always looking for ways to avoid paying what you owe.\",\n",
       "  'functional': 'I want us both to work together to find a solution that is equitable and fair for everyone involved.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data_dolphin[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model_name = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model:str):\n",
    "    \"\"\"\n",
    "    Generate embeddings for the input text using OpenAI's API.\n",
    "    \"\"\"\n",
    "    # text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input = [text], model=model)\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"So long and thanks for all the fish!\"\n",
    "r1 = get_embedding(text=text, model=emb_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03120167925953865,\n",
       " 0.010045701637864113,\n",
       " -0.016684768721461296,\n",
       " 0.00215172884054482,\n",
       " 0.01921393722295761]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embeddings of the first 20 examples in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 20 examples from the \"syn_data_gpt\" list \n",
    "syn_data_gpt_subset = syn_data_gpt[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_gpt = [get_embedding(text=text[\"dysfunctional\"], model=emb_model_name) for text in syn_data_gpt_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N data: 20\n",
      "Len vector: 1536\n"
     ]
    }
   ],
   "source": [
    "print(f\"N data: {len(embeddings_gpt)}\")\n",
    "print(f\"Len vector: {len(embeddings_gpt[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite Database\n",
    "\n",
    "### Option 1 (used)\n",
    "\n",
    "Create a .sql file with the following code\n",
    "\n",
    "```\n",
    "CREATE TABLE examples (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    dysfunctional TEXT NOT NULL,\n",
    "    embedding TEXT NOT NULL,\n",
    "    functional TEXT NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "and run the functions below.\n",
    "\n",
    "### Option 2\n",
    "\n",
    "To create a SQLite Database run the following bash code.\n",
    "\n",
    "1. Create a new database named \"emb_examples.db\"\n",
    "    ```\n",
    "    sqlite3 emb_examples.db\n",
    "    ```\n",
    "\n",
    "2. Create the table (the vector dimension must be equal to the model's embedding size, here **1536**)\n",
    "    ```\n",
    "    CREATE TABLE examples (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        example_text TEXT NOT NULL,\n",
    "        embedding VECTOR(1536)\n",
    "    );\n",
    "    ```\n",
    "\n",
    "3. Exit this program\n",
    "    ```\n",
    "    .quit\n",
    "    ``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(file_name_sql:str=\"create_bd.sql\", file_name_bd:str=\"database/emb_examples.db\"):\n",
    "\n",
    "    file_path = Path(file_name_bd)\n",
    "\n",
    "    if file_path.exists():\n",
    "        print(\"The table already exists!\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"Creating table...\")\n",
    "        with open(file_name_sql, 'r') as sql_file:\n",
    "            sql_script = sql_file.read()\n",
    "        db = sqlite3.connect(file_name_bd)\n",
    "        cursor = db.cursor()\n",
    "        cursor.executescript(sql_script)\n",
    "        db.commit()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table...\n"
     ]
    }
   ],
   "source": [
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embeddings(examples:list, embeddings:list, path_db:str=\"database/emb_examples.db\"):\n",
    "    con = sqlite3.connect(path_db)\n",
    "    with con:\n",
    "        for ex, emb in zip(examples, embeddings):\n",
    "            con.execute(\n",
    "                \"INSERT INTO examples (dysfunctional, embedding, functional) VALUES (?, ?, ?)\",\n",
    "                (ex[\"dysfunctional\"], json.dumps(emb), ex[\"functional\"])\n",
    "            )\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_embeddings(\n",
    "    examples=syn_data_gpt_subset,\n",
    "    embeddings=embeddings_gpt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dailogy_sin_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
